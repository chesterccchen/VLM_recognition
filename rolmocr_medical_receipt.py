# HOST YOUR OPENAI COMPATIBLE API WITH THE FOLLOWING COMMAND in VLLM:
# export VLLM_USE_V1=1
# vllm serve reducto/RolmOCR 

from openai import OpenAI
import base64
import time
import threading
import argparse
from PIL import Image
import io

client = OpenAI(api_key="123", base_url="http://localhost:8000/v1")

model = "reducto/RolmOCR"

def compress_image(image_path, max_size=1700, quality=85):
    """
    å£“ç¸®åœ–ç‰‡ï¼Œä¿æŒåŸå§‹å¯¬é«˜æ¯”ï¼Œä¸å¼·åˆ¶èª¿æ•´ç‚ºæ­£æ–¹å½¢ã€‚
    :param image_path: åœ–ç‰‡è·¯å¾‘
    :param max_size: æœ€å¤§é‚Šé•·ï¼ˆå–®é‚Šï¼‰ï¼Œé è¨­ç‚º 1600
    :param quality: JPEG å£“ç¸®å“è³ªï¼Œé è¨­ç‚º 85
    :return: base64 ç·¨ç¢¼çš„åœ–ç‰‡æ•¸æ“š
    """
    # æ‰“é–‹åœ–ç‰‡
    img = Image.open(image_path)
    
    # æª¢æŸ¥åœ–ç‰‡åŸå§‹å°ºå¯¸
    original_width, original_height = img.size
    #print(f"åŸå§‹åœ–ç‰‡å°ºå¯¸ï¼š{original_width}x{original_height}")
    
    # è¨ˆç®—åŸå§‹å¯¬é«˜æ¯”
    aspect_ratio = original_width / original_height
    #print(f"åŸå§‹å¯¬é«˜æ¯”ï¼š{aspect_ratio:.2f}")
    
    # å¦‚æœåœ–ç‰‡æœ€å¤§é‚Šé•·å°æ–¼ max_sizeï¼Œå‰‡ä¸éœ€è¦å£“ç¸®
    if max(original_width, original_height) >= max_size:
        print(f"åœ–ç‰‡æœ€å¤§é‚Šé•·é«˜æ–¼ {max_size}ï¼Œé€²è¡Œå£“ç¸®...")
        # ä½¿ç”¨ thumbnail ç¸®æ”¾åœ–ç‰‡ï¼Œä¿æŒå¯¬é«˜æ¯”
        img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    
    print("\n")
    # ç²å–ç¸®æ”¾å¾Œçš„å°ºå¯¸
    new_width, new_height = img.size
   # print(f"ç¸®æ”¾å¾Œåœ–ç‰‡å°ºå¯¸ï¼š{new_width}x{new_height}")
    
    # ä¿å­˜åœ–ç‰‡ä¸¦è½‰ç‚º base64
    output = io.BytesIO()
    img.save(output, format="JPEG", quality=quality)
    compressed_base64 = base64.b64encode(output.getvalue()).decode("utf-8")
    
    # æ‰“å°å£“ç¸®å¾Œçš„è³‡è¨Š
   # print(f"å£“ç¸®å¾Œ base64 é•·åº¦ï¼š{len(compressed_base64)}")
    
    return compressed_base64

def encode_image(image_path):
    """
    å°‡åœ–ç‰‡è½‰ç‚º base64 ç·¨ç¢¼ï¼Œä¸¦åœ¨éœ€è¦æ™‚é€²è¡Œå£“ç¸®ã€‚
    :param image_path: åœ–ç‰‡è·¯å¾‘
    :return: base64 ç·¨ç¢¼çš„å­—ç¬¦ä¸²
    """
    # ä½¿ç”¨ compress_image å‡½æ•¸è™•ç†åœ–ç‰‡
    img_base64 = compress_image(image_path, max_size=1700, quality=85)
    return img_base64

def VLM_ocr(img_base64):
    img_data = base64.b64decode(img_base64)
    img = Image.open(io.BytesIO(img_data))
    width, height = img.size
    # å‘¼å« OpenAI API
    response = client.chat.completions.create(
        model=model,
       messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{img_base64}"},
                    },
                    {
                        "type": "text",
                        #"text": """å®Œæ•´çš„å°å‡ºé€™å¼µåœ–ç‰‡ä¸Šçš„æ‰€æœ‰å…§å®¹ï¼ŒåŒ…å«æ¨™é¡Œï¼Œç—…æ‚£è³‡è¨Šï¼Œè¡¨æ ¼ï¼Œæ”¶è²»é …ç›®ï¼Œé‡‘é¡ï¼Œæ—¥æœŸï¼Œåºè™Ÿï¼Œå…¶ä»–è³‡è¨Šç­‰ç­‰ï¼Œä¸¦ä¿ç•™è¡¨æ ¼è³‡è¨Šï¼ŒçµæŸå¾Œå°å‡º"END_OF_OUTPUT"  """
                        "text": """å®Œæ•´çš„å¾åœ–ç‰‡çš„æœ€ä¸Šé¢åˆ°æœ€ä¸‹é¢å°å‡ºé€™å¼µåœ–ç‰‡ä¸Šçš„æ‰€æœ‰å…§å®¹å’Œæ–‡å­—ï¼Œä¸¦ä¿ç•™è¡¨æ ¼è³‡è¨Šï¼ŒçµæŸå¾Œå°å‡º"END_OF_OUTPUT"  """
                        
                    },
                ],
            }
        ],
        stream=True,
        temperature=0.2,
        #presence_penalty=1,
        max_tokens=4000,
        stop=["END_OF_OUTPUT"],
        #frequency_penalty=1.0,
    )
    # è¨ˆç®—æ¨ç†æ™‚é–“
    full_text = ""
    for chunk in response:
        if chunk.choices[0].delta.content is not None:
          partial = chunk.choices[0].delta.content
          print(partial, end="", flush=True)
          full_text += partial
   # print("\nğŸ“¥ å…¨æ–‡çµæŸç”Ÿæˆã€‚")

    # è¿”å›çµæœ
    #return response.choices[0].message.content
    return full_text

def main():
    # è¨­å®šå‘½ä»¤åˆ—åƒæ•¸è§£æ
    parser = argparse.ArgumentParser(description='OCR processing with RolmOCR')
    parser.add_argument('--image', 
                        type=str, 
                        default="/home/chester/rolmocr/tw_einvoice/1005.jpg",
                        help='Path to the test image file')
    
    # è§£æåƒæ•¸
    args = parser.parse_args()
    # ä½¿ç”¨è§£æå¾Œçš„è·¯å¾‘
    test_img_path = args.image
    img_base64 = encode_image(test_img_path)

    print("\nğŸ“¥ å…¨æ–‡ç”Ÿæˆçµæœ:\n")

    start_time = time.time()
    result_page = VLM_ocr(img_base64)
    end_time = time.time()
    print(f"è¨ˆç®—æ•´å¼µæ™‚é–“: {end_time - start_time}")

if __name__ == "__main__":
    main()